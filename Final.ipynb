{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfe410ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "from keras.models import model_from_json\n",
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df716c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from flask import Flask, render_template_string\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Configure the database\n",
    "current_dir = os.getcwd()  # Get the current working directory\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///' + os.path.join(current_dir, \"db_4.sqlite3\")  # Replace with your actual db file name\n",
    "app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False\n",
    "app.secret_key = 'your_secret_key'\n",
    "\n",
    "# Initialize SQLAlchemy\n",
    "db = SQLAlchemy(app)\n",
    "\n",
    "# Define the DSA_22_Batch model for the table\n",
    "class DSA22Batch(db.Model):\n",
    "    __tablename__ = 'dsa_22_batch'\n",
    "    year = db.Column(db.String, nullable=False)\n",
    "    semester = db.Column(db.String, nullable=False)\n",
    "    course = db.Column(db.String, nullable=False)\n",
    "    instructor_id = db.Column(db.Integer, nullable=False)\n",
    "    date = db.Column(db.Date, nullable=False)\n",
    "    # Adding all the student IDs as columns\n",
    "    BT22CSD001 = db.Column(db.Integer)\n",
    "    BT22CSD002 = db.Column(db.Integer)\n",
    "    BT22CSD003 = db.Column(db.Integer)\n",
    "    BT22CSD004 = db.Column(db.Integer)\n",
    "    BT22CSD005 = db.Column(db.Integer)\n",
    "    BT22CSD006 = db.Column(db.Integer)\n",
    "    BT22CSD007 = db.Column(db.Integer)\n",
    "    BT22CSD008 = db.Column(db.Integer)\n",
    "    BT22CSD009 = db.Column(db.Integer)\n",
    "    BT22CSD010 = db.Column(db.Integer)\n",
    "    BT22CSD011 = db.Column(db.Integer)\n",
    "    BT22CSD012 = db.Column(db.Integer)\n",
    "    BT22CSD013 = db.Column(db.Integer)\n",
    "    BT22CSD014 = db.Column(db.Integer)\n",
    "    BT22CSD015 = db.Column(db.Integer)\n",
    "    BT22CSD016 = db.Column(db.Integer)\n",
    "    BT22CSD017 = db.Column(db.Integer)\n",
    "    BT22CSD018 = db.Column(db.Integer)\n",
    "    BT22CSD019 = db.Column(db.Integer)\n",
    "    BT22CSD020 = db.Column(db.Integer)\n",
    "    BT22CSD021 = db.Column(db.Integer)\n",
    "    BT22CSD022 = db.Column(db.Integer)\n",
    "    BT22CSD023 = db.Column(db.Integer)\n",
    "    BT22CSD024 = db.Column(db.Integer)\n",
    "    BT22CSD025 = db.Column(db.Integer)\n",
    "    BT22CSD026 = db.Column(db.Integer)\n",
    "    BT22CSD027 = db.Column(db.Integer)\n",
    "    BT22CSD028 = db.Column(db.Integer)\n",
    "    BT22CSD029 = db.Column(db.Integer)\n",
    "    BT22CSD030 = db.Column(db.Integer)\n",
    "    BT22CSD031 = db.Column(db.Integer)\n",
    "    BT22CSD032 = db.Column(db.Integer)\n",
    "    BT22CSD033 = db.Column(db.Integer)\n",
    "    BT22CSD034 = db.Column(db.Integer)\n",
    "    BT22CSD035 = db.Column(db.Integer)\n",
    "    BT22CSD036 = db.Column(db.Integer)\n",
    "    BT22CSD037 = db.Column(db.Integer)\n",
    "    BT22CSD038 = db.Column(db.Integer)\n",
    "    BT22CSD039 = db.Column(db.Integer)\n",
    "    BT22CSD040 = db.Column(db.Integer)\n",
    "    BT22CSD041 = db.Column(db.Integer)\n",
    "    BT22CSD042 = db.Column(db.Integer)\n",
    "    BT22CSD043 = db.Column(db.Integer)\n",
    "    BT22CSD044 = db.Column(db.Integer)\n",
    "    BT22CSD045 = db.Column(db.Integer)\n",
    "    BT22CSD046 = db.Column(db.Integer)\n",
    "    BT22CSD047 = db.Column(db.Integer)\n",
    "    BT22CSD048 = db.Column(db.Integer)\n",
    "    BT22CSD049 = db.Column(db.Integer)\n",
    "    BT22CSD050 = db.Column(db.Integer)\n",
    "    BT22CSD051 = db.Column(db.Integer)\n",
    "    BT22CSD052 = db.Column(db.Integer)\n",
    "    BT22CSD053 = db.Column(db.Integer)\n",
    "    BT22CSD054 = db.Column(db.Integer)\n",
    "    BT22CSD055 = db.Column(db.Integer)\n",
    "    BT22CSD056 = db.Column(db.Integer)\n",
    "    BT22CSD057 = db.Column(db.Integer)\n",
    "    BT22CSD058 = db.Column(db.Integer)\n",
    "    BT22CSD059 = db.Column(db.Integer)\n",
    "    BT22CSD060 = db.Column(db.Integer)\n",
    "    BT22CSD061 = db.Column(db.Integer)\n",
    "    BT22CSD062 = db.Column(db.Integer)\n",
    "    BT22CSD063 = db.Column(db.Integer)\n",
    "    BT22CSD064 = db.Column(db.Integer)\n",
    "    BT22CSD065 = db.Column(db.Integer)\n",
    "    __table_args__ = (\n",
    "        db.PrimaryKeyConstraint('year', 'semester', 'course', 'instructor_id','date'),\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c7cf982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def add_record_to_database(year, semester, course, instructor_id, date, predict):\n",
    "    \"\"\"\n",
    "    Add a new record to the DSA22Batch table.\n",
    "\n",
    "    Args:\n",
    "        year (str): Academic year.\n",
    "        semester (str): Semester.\n",
    "        course (str): Course name.\n",
    "        instructor_id (int): Instructor ID.\n",
    "        date (str): Date in YYYY-MM-DD format.\n",
    "        predict (list): List of student IDs to be marked as 1.\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary for student data with all student IDs set to None\n",
    "    student_data = {f\"BT22CSD{i:03d}\": None for i in range(1, 66)}\n",
    "    \n",
    "    # Set the value to 1 for student IDs present in the predict list\n",
    "    for student_id in student_data:\n",
    "        if student_id in predict:\n",
    "            student_data[student_id] = 1\n",
    "        else:\n",
    "            student_data[student_id] = 0\n",
    "    # Parse the date string into a datetime object\n",
    "    record_date = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "    \n",
    "    # Create a new record\n",
    "    new_record = DSA22Batch(\n",
    "        year=year,\n",
    "        semester=semester,\n",
    "        course=course,\n",
    "        instructor_id=instructor_id,\n",
    "        date=record_date,\n",
    "        **student_data\n",
    "    )\n",
    "    print(new_record)\n",
    "    # Add the record to the database\n",
    "    try:\n",
    "        db.session.add(new_record)\n",
    "        db.session.commit()\n",
    "        print(\"Record added successfully.\")\n",
    "    except Exception as e:\n",
    "        db.session.rollback()\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "\n",
    "# with app.app_context():\n",
    "#     # Example values\n",
    "#     year = \"2024\"\n",
    "#     semester = \"Fall\"\n",
    "#     course = \"Data Science\"\n",
    "#     instructor_id = 101\n",
    "#     date = \"2024-12-06\"\n",
    "#     predict = [\"BT22CSD002\", \"BT22CSD015\", \"BT22CSD030\"]\n",
    "\n",
    "#     add_record_to_database(year, semester, course, instructor_id, date, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ccb40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_faces(image_path,Year,Sem,course,instructor_id,date, padding=20):\n",
    "    \"\"\"\n",
    "    Extract faces from an image with additional padding around each face.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        padding (int): Number of pixels to expand each edge of the face bounding box.\n",
    "    \"\"\"\n",
    "    print(image_path,Year,Sem,course,instructor_id,date)\n",
    "    # Load the image into memory\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    \n",
    "    # Find all face locations in the image\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    \n",
    "    # Get the base name of the image for folder naming\n",
    "    image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    extracted_folder = f\"{image_name}_extracted_combined_2_flask\"\n",
    "    \n",
    "    # Create a folder to save extracted faces if it doesn't exist\n",
    "    if not os.path.exists(extracted_folder):\n",
    "        os.makedirs(extracted_folder)\n",
    "    \n",
    "    # Initialize OpenCV for saving the cropped faces\n",
    "    original_image = cv2.imread(image_path)\n",
    "    image_height, image_width, _ = original_image.shape\n",
    "    \n",
    "    # Extract and save each face with increased cropping edges\n",
    "    for i, (top, right, bottom, left) in enumerate(face_locations):\n",
    "        # Increase the crop boundaries with padding\n",
    "        top = max(0, top - padding)\n",
    "        right = min(image_width, right + padding)\n",
    "        bottom = min(image_height, bottom + padding)\n",
    "        left = max(0, left - padding)\n",
    "        \n",
    "        # Crop the face from the original image using the adjusted coordinates\n",
    "        face_image = original_image[top:bottom, left:right]\n",
    "        \n",
    "        # Save the cropped face in the folder\n",
    "        face_filename = os.path.join(extracted_folder, f\"face_{i+1}.jpg\")\n",
    "        cv2.imwrite(face_filename, face_image)\n",
    "    \n",
    "    print(f\"Extracted faces saved in folder: {extracted_folder}\")\n",
    "    \n",
    "    # Load the model architecture\n",
    "    with open('vggface_resnet50_model_59.json', 'r') as json_file:\n",
    "        model_json = json_file.read()\n",
    "\n",
    "    # Recreate the model from the JSON\n",
    "    model = model_from_json(model_json)\n",
    "    model.load_weights('vggface_resnet50_weights_59.h5')\n",
    "    feature_list = np.array(pickle.load(open('embedding3.pkl', 'rb')))\n",
    "    filenames = pickle.load(open('students3.pkl', 'rb'))\n",
    "    model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "    detector = MTCNN()\n",
    "    filenames = pickle.load(open('students3.pkl', 'rb'))\n",
    "\n",
    "    folder_path = extracted_folder\n",
    "\n",
    "    expected_dict = {\n",
    "        \"face_1\": \"BT22CSD031\",\n",
    "        \"face_2\": \"BT22CSD015\",\n",
    "        \"face_3\": \"BT22CSD040\",\n",
    "        \"face_4\": \"BT22CSD058\",\n",
    "        \"face_5\": \"BT22CSD028\",\n",
    "        \"face_6\": \"BT22CSD054\",\n",
    "        \"face_7\": \"BT22CSD012\",\n",
    "        \"face_8\": \"BT22CSD036\",\n",
    "        \"face_9\": \"BT22CSD035\",\n",
    "        \"face_10\": \"BT22CSD024\",\n",
    "        \"face_11\": \"BT22CSD039\",\n",
    "        \"face_12\": \"BT22CSD011\",\n",
    "        \"face_13\": \"BT22CSD050\",\n",
    "        \"face_14\": \"BT22CSD017\",\n",
    "        \"face_15\": \"BT22CSD049\",\n",
    "        \"face_16\": \"BT22CSD041\",\n",
    "        \"face_17\": \"BT22CSD055\",\n",
    "        \"face_18\": \"BT22CSD014\",\n",
    "        \"face_19\": \"BT22CSD034\",\n",
    "        \"face_20\": \"BT22CSD020\",\n",
    "        \"face_21\": \"BT22CSD046\",\n",
    "        \"face_22\": \"BT22CSD032\",\n",
    "        \"face_23\": \"BT22CSD037\",\n",
    "    }\n",
    "    \n",
    "    match_count = 0\n",
    "    predictions = []\n",
    "    print(expected_dict)\n",
    "    \n",
    "    print(folder_path)\n",
    "    for filename in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        Sampler = cv2.imread(image_path)\n",
    "    \n",
    "        results = detector.detect_faces(Sampler)\n",
    "        if Sampler is None:\n",
    "            raise ValueError(f\"Image at {image_path} could not be loaded. Please check the path.\")\n",
    "        results = detector.detect_faces(Sampler)\n",
    "        if results:\n",
    "            x, y, width, height = results[0]['box']\n",
    "    \n",
    "            # Clamp bounding box to image dimensions\n",
    "            img_height, img_width = Sampler.shape[:2]\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            width = min(width, img_width - x)\n",
    "            height = min(height, img_height - y)\n",
    "    \n",
    "            # Crop and preprocess face\n",
    "            face = Sampler[y:y + height, x:x + width]\n",
    "            if face.size == 0:\n",
    "                continue\n",
    "            \n",
    "            image = Image.fromarray(face)\n",
    "            image = image.resize((224, 224))\n",
    "            face_array = np.asarray(image).astype('float32')\n",
    "            expanded_img = np.expand_dims(face_array, axis=0)\n",
    "            preprocessed_img = preprocess_input(expanded_img)\n",
    "    \n",
    "            # Model prediction and similarity calculation\n",
    "            result = model.predict(preprocessed_img).flatten()\n",
    "    \n",
    "            similarity = []\n",
    "            for i in range(len(feature_list)):\n",
    "                sim = cosine_similarity(result.reshape(1, -1), feature_list[i].reshape(1, -1))\n",
    "                similarity.append(sim)\n",
    "    \n",
    "            enumerated = list(enumerate(similarity))\n",
    "            index_pos = sorted(enumerated, reverse=True, key=lambda x: x[1])[0][0]\n",
    "            predicted_value = filenames[index_pos][24:34]\n",
    "    \n",
    "            # Check match\n",
    "            expected_value = expected_dict.get(filename.split('.')[0])  # Get the value for the current file\n",
    "            predictions.append( predicted_value)\n",
    "            if expected_value == predicted_value:\n",
    "                match_count += 1\n",
    "                print(f\"File: {filename}, Predicted: {predicted_value}, Matched: YES\")\n",
    "            else:\n",
    "                print(f\"File: {filename}, Predicted: {predicted_value}, Matched: NO\")\n",
    "        else:\n",
    "            print(f\"No faces detected in {filename}.\")\n",
    "    \n",
    "    print(f\"Total matches: {match_count}\")\n",
    "    \n",
    "    predict = predictions\n",
    "#     with app.app_context():\n",
    "#         add_record_to_database(Year, Sem, course, instructor_id, date, predict)\n",
    "    \n",
    "    print(predict)\n",
    "    if(course==\"CSL422\"):\n",
    "        csv_file_path = \"C:/saii/predicted_ML.csv\"\n",
    "    elif(course==\"CSL302\"):\n",
    "        csv_file_path = \"C:/saii/predicted_CN.csv\"\n",
    "    elif(course==\"CSL301\"):\n",
    "        csv_file_path = \"C:/saii/predicted_DBMS.csv\"\n",
    "    elif(course==\"CSL311\"):\n",
    "        csv_file_path = \"C:/saii/predicted_DPS.csv\"\n",
    "    elif(course==\"CSL410\"):\n",
    "        csv_file_path = \"C:/saii/predicted_AI.csv\"\n",
    "\n",
    "    # Read the existing CSV and append the 'date' column with 0/1 values based on matching IDs\n",
    "    with open(csv_file_path, mode='r', newline='', encoding='utf-8') as infile:\n",
    "        # Read the CSV data\n",
    "        reader = csv.DictReader(infile)\n",
    "        fieldnames = reader.fieldnames + [str(date)]  # Add 'date' to the fieldnames\n",
    "    \n",
    "    # Prepare the data to be written\n",
    "        rows = []\n",
    "        for row in reader:\n",
    "            # Check if the 'id' is in the 'predict' list\n",
    "            if row['ID'] in predict:\n",
    "                row[str(date)] = '1'  # If matched, set date as 1\n",
    "            else:\n",
    "                row[str(date)] = '0'  # Otherwise, set date as 0\n",
    "            rows.append(row)\n",
    "    \n",
    "    # Write the updated data back to the CSV file\n",
    "    with open(csv_file_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    \n",
    "        # Write the header\n",
    "        writer.writeheader()\n",
    "    \n",
    "        # Write the updated rows\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    print(f\"Updated {csv_file_path} with the 'date' column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b68299e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_faces(image_path, Year, Sem, course, instructor_id, date, padding=20):\n",
    "    \"\"\"\n",
    "    Extract faces from an image with additional padding around each face.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "        padding (int): Number of pixels to expand each edge of the face bounding box.\n",
    "    \"\"\"\n",
    "    print(image_path, Year, Sem, course, instructor_id, date)\n",
    "    # Load the image into memory\n",
    "    image = face_recognition.load_image_file(image_path)\n",
    "    \n",
    "    # Find all face locations in the image\n",
    "    face_locations = face_recognition.face_locations(image)\n",
    "    \n",
    "    # Get the base name of the image for folder naming\n",
    "    image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    extracted_folder = f\"{image_name}_extracted_combined_2_flask\"\n",
    "    \n",
    "    # Create a folder to save extracted faces if it doesn't exist\n",
    "    if not os.path.exists(extracted_folder):\n",
    "        os.makedirs(extracted_folder)\n",
    "    \n",
    "    # Initialize OpenCV for saving the cropped faces\n",
    "    original_image = cv2.imread(image_path)\n",
    "    image_height, image_width, _ = original_image.shape\n",
    "    \n",
    "    # Extract and save each face with increased cropping edges\n",
    "    for i, (top, right, bottom, left) in enumerate(face_locations):\n",
    "        # Increase the crop boundaries with padding\n",
    "        top = max(0, top - padding)\n",
    "        right = min(image_width, right + padding)\n",
    "        bottom = min(image_height, bottom + padding)\n",
    "        left = max(0, left - padding)\n",
    "        \n",
    "        # Crop the face from the original image using the adjusted coordinates\n",
    "        face_image = original_image[top:bottom, left:right]\n",
    "        \n",
    "        # Save the cropped face in the folder\n",
    "        face_filename = os.path.join(extracted_folder, f\"face_{i+1}.jpg\")\n",
    "        cv2.imwrite(face_filename, face_image)\n",
    "    \n",
    "    print(f\"Extracted faces saved in folder: {extracted_folder}\")\n",
    "    \n",
    "    # Load the model architecture\n",
    "    with open('vggface_resnet50_model_59.json', 'r') as json_file:\n",
    "        model_json = json_file.read()\n",
    "\n",
    "    # Recreate the model from the JSON\n",
    "    model = model_from_json(model_json)\n",
    "    model.load_weights('vggface_resnet50_weights_59.h5')\n",
    "    feature_list = np.array(pickle.load(open('embedding3.pkl', 'rb')))\n",
    "    filenames = pickle.load(open('students3.pkl', 'rb'))\n",
    "    model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "    detector = MTCNN()\n",
    "    filenames = pickle.load(open('students3.pkl', 'rb'))\n",
    "\n",
    "    folder_path = extracted_folder\n",
    "\n",
    "    expected_dict = {\n",
    "        \"face_1\": \"BT22CSD031\",\n",
    "        \"face_2\": \"BT22CSD015\",\n",
    "        \"face_3\": \"BT22CSD040\",\n",
    "        \"face_4\": \"BT22CSD058\",\n",
    "        \"face_5\": \"BT22CSD028\",\n",
    "        \"face_6\": \"BT22CSD054\",\n",
    "        \"face_7\": \"BT22CSD012\",\n",
    "        \"face_8\": \"BT22CSD036\",\n",
    "        \"face_9\": \"BT22CSD035\",\n",
    "        \"face_10\": \"BT22CSD024\",\n",
    "        \"face_11\": \"BT22CSD039\",\n",
    "        \"face_12\": \"BT22CSD011\",\n",
    "        \"face_13\": \"BT22CSD050\",\n",
    "        \"face_14\": \"BT22CSD017\",\n",
    "        \"face_15\": \"BT22CSD049\",\n",
    "        \"face_16\": \"BT22CSD041\",\n",
    "        \"face_17\": \"BT22CSD055\",\n",
    "        \"face_18\": \"BT22CSD014\",\n",
    "        \"face_19\": \"BT22CSD034\",\n",
    "        \"face_20\": \"BT22CSD020\",\n",
    "        \"face_21\": \"BT22CSD046\",\n",
    "        \"face_22\": \"BT22CSD032\",\n",
    "        \"face_23\": \"BT22CSD037\",\n",
    "    }\n",
    "    \n",
    "    match_count = 0\n",
    "    predictions = []\n",
    "    print(expected_dict)\n",
    "    \n",
    "    print(folder_path)\n",
    "    for filename in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the image\n",
    "        Sampler = cv2.imread(image_path)\n",
    "        \n",
    "        # Check if the image is valid (not None)\n",
    "        if Sampler is None:\n",
    "            print(f\"Image at {image_path} could not be loaded. Skipping this file.\")\n",
    "            continue\n",
    "        \n",
    "        # Now proceed with face detection\n",
    "        results = detector.detect_faces(Sampler)\n",
    "        \n",
    "        if results:\n",
    "            x, y, width, height = results[0]['box']\n",
    "\n",
    "            # Clamp bounding box to image dimensions\n",
    "            img_height, img_width = Sampler.shape[:2]\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            width = min(width, img_width - x)\n",
    "            height = min(height, img_height - y)\n",
    "\n",
    "            # Crop and preprocess face\n",
    "            face = Sampler[y:y + height, x:x + width]\n",
    "            if face.size == 0:\n",
    "                continue\n",
    "\n",
    "            image = Image.fromarray(face)\n",
    "            image = image.resize((224, 224))\n",
    "            face_array = np.asarray(image).astype('float32')\n",
    "            expanded_img = np.expand_dims(face_array, axis=0)\n",
    "            preprocessed_img = preprocess_input(expanded_img)\n",
    "\n",
    "            # Model prediction and similarity calculation\n",
    "            result = model.predict(preprocessed_img).flatten()\n",
    "\n",
    "            similarity = []\n",
    "            for i in range(len(feature_list)):\n",
    "                sim = cosine_similarity(result.reshape(1, -1), feature_list[i].reshape(1, -1))\n",
    "                similarity.append(sim)\n",
    "\n",
    "            enumerated = list(enumerate(similarity))\n",
    "            index_pos = sorted(enumerated, reverse=True, key=lambda x: x[1])[0][0]\n",
    "            predicted_value = filenames[index_pos][24:34]\n",
    "\n",
    "            # Check match\n",
    "            expected_value = expected_dict.get(filename.split('.')[0])  # Get the value for the current file\n",
    "            predictions.append(predicted_value)\n",
    "            if expected_value == predicted_value:\n",
    "                match_count += 1\n",
    "                print(f\"File: {filename}, Predicted: {predicted_value}, Matched: YES\")\n",
    "            else:\n",
    "                print(f\"File: {filename}, Predicted: {predicted_value}, Matched: NO\")\n",
    "        else:\n",
    "            print(f\"No faces detected in {filename}.\")\n",
    "    \n",
    "    print(f\"Total matches: {match_count}\")\n",
    "    predict = predictions\n",
    "\n",
    "    if course == \"CSL422\":\n",
    "        csv_file_path = \"C:/saii/predicted_ML.csv\"\n",
    "    elif course == \"CSL312\":\n",
    "        csv_file_path = \"C:/saii/predicted_CN.csv\"\n",
    "    elif course == \"CSL301\":\n",
    "        csv_file_path = \"C:/saii/predicted_DBMS.csv\"\n",
    "    elif course == \"CSL311\":\n",
    "        csv_file_path = \"C:/saii/predicted_DPS.csv\"\n",
    "    elif course == \"CSL410\":\n",
    "        csv_file_path = \"C:/saii/predicted_AI.csv\"\n",
    "\n",
    "    # Read the existing CSV and append the 'date' column with 0/1 values based on matching IDs\n",
    "    with open(csv_file_path, mode='r', newline='', encoding='utf-8') as infile:\n",
    "        # Read the CSV data\n",
    "        reader = csv.DictReader(infile)\n",
    "        fieldnames = reader.fieldnames + [str(date)]  # Add 'date' to the fieldnames\n",
    "    \n",
    "        # Prepare the data to be written\n",
    "        rows = []\n",
    "        for row in reader:\n",
    "            # Check if the 'id' is in the 'predict' list\n",
    "            if row['ID'] in predict:\n",
    "                row[str(date)] = '1'  # If matched, set date as 1\n",
    "            else:\n",
    "                row[str(date)] = '0'  # Otherwise, set date as 0\n",
    "            rows.append(row)\n",
    "    \n",
    "    # Write the updated data back to the CSV file\n",
    "    with open(csv_file_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    \n",
    "        # Write the header\n",
    "        writer.writeheader()\n",
    "    \n",
    "        # Write the updated rows\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    print(f\"Updated {csv_file_path} with the 'date' column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef34fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 28/04/2025_14:37:13\n",
      "Course: CSL312\n",
      "Instructor ID: 2\n",
      "C:/saii/uploads\\grp_img_1.jpg 3rd Year 5th Sem CSL312 2 28/04/2025_14:37:13\n",
      "Extracted faces saved in folder: grp_img_1_extracted_combined_2_flask\n",
      "{'face_1': 'BT22CSD031', 'face_2': 'BT22CSD015', 'face_3': 'BT22CSD040', 'face_4': 'BT22CSD058', 'face_5': 'BT22CSD028', 'face_6': 'BT22CSD054', 'face_7': 'BT22CSD012', 'face_8': 'BT22CSD036', 'face_9': 'BT22CSD035', 'face_10': 'BT22CSD024', 'face_11': 'BT22CSD039', 'face_12': 'BT22CSD011', 'face_13': 'BT22CSD050', 'face_14': 'BT22CSD017', 'face_15': 'BT22CSD049', 'face_16': 'BT22CSD041', 'face_17': 'BT22CSD055', 'face_18': 'BT22CSD014', 'face_19': 'BT22CSD034', 'face_20': 'BT22CSD020', 'face_21': 'BT22CSD046', 'face_22': 'BT22CSD032', 'face_23': 'BT22CSD037'}\n",
      "grp_img_1_extracted_combined_2_flask\n",
      "Image at grp_img_1_extracted_combined_2_flask\\.ipynb_checkpoints could not be loaded. Skipping this file.\n",
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B302E40CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B3030B6670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "File: face_1.jpg, Predicted: BT22CSD031, Matched: YES\n",
      "File: face_10.jpg, Predicted: BT22CSD024, Matched: YES\n",
      "File: face_11.jpg, Predicted: BT22CSD039, Matched: YES\n",
      "File: face_12.jpg, Predicted: BT22CSD011, Matched: YES\n",
      "File: face_13.jpg, Predicted: BT22CSD024, Matched: NO\n",
      "File: face_14.jpg, Predicted: BT22CSD017, Matched: YES\n",
      "File: face_15.jpg, Predicted: BT22CSD061, Matched: NO\n",
      "File: face_16.jpg, Predicted: BT22CSD041, Matched: YES\n",
      "File: face_17.jpg, Predicted: BT22CSD055, Matched: YES\n",
      "File: face_18.jpg, Predicted: BT22CSD014, Matched: YES\n",
      "File: face_19.jpg, Predicted: BT22CSD034, Matched: YES\n",
      "File: face_2.jpg, Predicted: BT22CSD015, Matched: YES\n",
      "File: face_20.jpg, Predicted: BT22CSD042, Matched: NO\n",
      "File: face_21.jpg, Predicted: BT22CSD046, Matched: YES\n",
      "File: face_22.jpg, Predicted: BT22CSD054, Matched: NO\n",
      "File: face_23.jpg, Predicted: BT22CSD037, Matched: YES\n",
      "File: face_3.jpg, Predicted: BT22CSD040, Matched: YES\n",
      "File: face_4.jpg, Predicted: BT22CSD058, Matched: YES\n",
      "File: face_5.jpg, Predicted: BT22CSD028, Matched: YES\n",
      "File: face_6.jpg, Predicted: BT22CSD054, Matched: YES\n",
      "File: face_7.jpg, Predicted: BT22CSD012, Matched: YES\n",
      "File: face_8.jpg, Predicted: BT22CSD036, Matched: YES\n",
      "File: face_9.jpg, Predicted: BT22CSD035, Matched: YES\n",
      "Total matches: 19\n",
      "Updated C:/saii/predicted_CN.csv with the 'date' column.\n",
      "Moved C:/saii/uploads\\grp_img_1.jpg to C:/saii/safe\\grp_img_1.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "# Define the path to the folders\n",
    "folder_path = \"C:/saii/uploads\"\n",
    "safe_folder_path = \"C:/saii/safe\"\n",
    "folder_path_text = \"C:/saii/path.txt\"\n",
    "\n",
    "# Function to monitor the folder and call extract_face when an image is detected\n",
    "def monitor_folder(folder_path, safe_folder_path):\n",
    "    while True:\n",
    "        # List all files in the folder\n",
    "        files = os.listdir(folder_path)\n",
    "        \n",
    "        # Filter out image files (you can adjust the file types as per your requirement)\n",
    "        image_files = [f for f in files if f.lower().endswith(('png', 'jpg', 'jpeg', 'bmp', 'gif'))]\n",
    "        \n",
    "        # Check if there is at least one image file in the folder\n",
    "        if image_files:\n",
    "\n",
    "            if os.path.exists(folder_path_text):\n",
    "                with open(folder_path_text, 'r') as file:\n",
    "                    data = file.read()\n",
    "                    \n",
    "                    # Split the content into date, course, and instructor_id\n",
    "                    parts = data.split()\n",
    "                    if len(parts) >= 3:\n",
    "                        date = parts[0]\n",
    "                        course = parts[1]\n",
    "                        instructor_id = parts[2]\n",
    "                        \n",
    "                        # Print the extracted data\n",
    "                        print(f\"Date: {date}\")\n",
    "                        print(f\"Course: {course}\")\n",
    "                        print(f\"Instructor ID: {instructor_id}\")\n",
    "                with open(folder_path_text, 'w') as file:\n",
    "                    file.write(\"\")\n",
    "                    \n",
    "            image_path = os.path.join(folder_path, image_files[0])\n",
    "            # Call the extract_faces function (you need to define this function)\n",
    "            extract_faces(image_path,\"3rd Year\",\"5th Sem\",course,instructor_id,date)\n",
    "            \n",
    "            # Move the image to the 'safe' folder\n",
    "            safe_image_path = os.path.join(safe_folder_path, image_files[0])\n",
    "            shutil.move(image_path, safe_image_path)\n",
    "            print(f\"Moved {image_path} to {safe_image_path}\")\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Wait for some time before checking again\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "# Start monitoring the folder\n",
    "monitor_folder(folder_path, safe_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3273c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f021dd91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ef624c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa350e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3beb5202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d765c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
